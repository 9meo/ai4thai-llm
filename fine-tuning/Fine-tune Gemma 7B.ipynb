{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c97ccf4-d933-4a88-973d-1de15a189c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U torch --index-url https://download.pytorch.org/whl/cu117\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72b26bd9-d987-4fb7-99e0-3db80e9cf778",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U git+https://github.com/huggingface/transformers\n",
    "!pip install -q accelerate\n",
    "!pip install -q -i https://pypi.org/simple/ bitsandbytes\n",
    "!pip install -q -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "595c854e-6e50-4076-87ee-6f1e72134cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U git+https://github.com/huggingface/trl\n",
    "!pip install -q -U git+https://github.com/huggingface/peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8832d90c-6e48-423d-961e-d3d033388288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5113634c-e4d0-4e34-9327-cdf5b62bfbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52dc4b36-a967-4c78-b637-e15a23135af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "import bitsandbytes as bnb\n",
    "from trl import SFTTrainer\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "836390f4-4e53-4b63-a87c-d385cdebe003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d503c2f-803c-496e-ba0a-dafd640f15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('sepidmnorozy/Thai_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c0dbbef-6a49-4c4d-8a3c-273486d85d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the tweet enclosed in square brackets, \n",
    "            determine if it is positive or negative, and return the answer as \n",
    "            the corresponding sentiment label \"positive\" or  \"negative\"\n",
    "\n",
    "            [{data_point[\"text\"]}] = {data_point[\"label\"]}\n",
    "            \"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the tweet enclosed in square brackets, \n",
    "            determine if it is positive or negative, and return the answer as \n",
    "            the corresponding sentiment label \"positive\" or  \"negative\"\n",
    "\n",
    "            [{data_point[\"text\"]}] = \n",
    "\n",
    "            \"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f4b4c97-27dc-4fe9-a790-26eb3e0442db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 8103\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1153\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 2344\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd3be8da-7a50-4e15-8bf9-ec2af2cff1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data['test'].to_pandas()\n",
    "validation = data['validation'].to_pandas()\n",
    "train = data['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a652385-48bf-4446-a0b7-1ef4951c5145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(x):\n",
    "    if x==1:\n",
    "        return 'positive'\n",
    "    elif x==0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e617ff5-3858-460a-b69a-e733ed42db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label'] = train['label'].apply(lambda x: convert(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a68bca4-1e04-4b9d-a9c7-124b5492e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation['label'] = validation['label'].apply(lambda x: convert(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "377b0aad-f7db-4389-a63c-5307d2998316",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = test['label'].apply(lambda x: convert(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "431be3a7-6fba-48fb-b381-9d60d22f8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(train.apply(generate_prompt, axis=1), \n",
    "                       columns=[\"text\"])\n",
    "X_eval = pd.DataFrame(validation.apply(generate_prompt, axis=1), \n",
    "                      columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e5bdf6d-c64f-4f0c-bf49-5f22bfbd1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test.label\n",
    "X_test = pd.DataFrame(test.apply(generate_test_prompt, axis=1), columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40264c61-7bd6-4b80-ab11-3e7815a7144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_pandas(X_train)\n",
    "eval_data = Dataset.from_pandas(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86f777c1-0d82-4754-ae67-22d9be1315bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    \n",
    "    labels = ['positive',  'negative']\n",
    "    mapping = {'positive': 1, 'negative': 0, 'none':1,}\n",
    "    def map_func(x):\n",
    "        return mapping.get(x, 1)\n",
    "    \n",
    "    y_true = np.vectorize(map_func)(y_true)\n",
    "    y_pred = np.vectorize(map_func)(y_pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true)  # Get unique labels\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true)) \n",
    "                         if y_true[i] == label]\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1])\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48384ab6-3122-44ac-a139-53b44c8e537c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea388d743c14326971d08f46fd8b17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"google/gemma-2b\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5f69370-b19c-4579-a675-1fb28e80074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    for i in tqdm(range(len(X_test))):\n",
    "        prompt = X_test.iloc[i][\"text\"]\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        outputs = model.generate(**input_ids, max_new_tokens=1, temperature=0.0)\n",
    "        result = tokenizer.decode(outputs[0])\n",
    "        answer = result.split(\"=\")[-1].lower()\n",
    "        if \"positive\" in answer:\n",
    "            y_pred.append(\"positive\")\n",
    "        elif \"negative\" in answer:\n",
    "            y_pred.append(\"negative\")\n",
    "        elif \"neutral\" in answer:\n",
    "            y_pred.append(\"neutral\")\n",
    "        else:\n",
    "            y_pred.append(\"none\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a088a4a8-42f9-4614-ab04-5a614ab179d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 2344/2344 [01:44<00:00, 22.49it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test , model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae04782f-f2bb-4e45-9976-4fe21903768f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.647\n",
      "Accuracy for label 0: 0.444\n",
      "Accuracy for label 1: 0.941\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.44      0.60      1388\n",
      "           1       0.54      0.94      0.68       956\n",
      "\n",
      "    accuracy                           0.65      2344\n",
      "   macro avg       0.73      0.69      0.64      2344\n",
      "weighted avg       0.76      0.65      0.63      2344\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[616 772]\n",
      " [ 56 900]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6460faec-b36c-4fe9-96d8-2535da774fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'none',\n",
       " 'none',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'positive',\n",
       " 'none',\n",
       " 'none',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1a2aa7a-fe64-4697-9829-11913ae07f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0a0ed3cc3c447cb793167b5031c4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8103 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=\"all-linear\",\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"logs\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=0,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    report_to=\"tensorboard\",\n",
    "    do_eval=False,\n",
    "    evaluation_strategy=\"no\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    "    max_seq_length=1024,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73c876b9-3d64-446d-bd25-d37c25bff595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3036' max='3036' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3036/3036 2:06:27, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.604300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.366600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>2.163600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.792800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>2.180700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.818100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>2.225200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.813900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.172600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.752800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.052400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.702600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.746400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.761400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.085400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.789200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.014100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.692300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.034100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.715700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.098100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.732900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.726500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>1.982700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.731600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>1.911400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.661400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>1.951100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.688200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>1.986500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.751700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>1.914600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.698500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>1.886200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.677900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>1.847600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.699800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>1.723300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.082200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>1.295700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>1.347800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.153800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>1.317100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.051400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>1.278500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>1.349900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.159300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>1.347700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>1.119400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>1.351400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.129400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>1.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>1.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>1.268600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>1.314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>1.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>1.337300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.127100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>1.341100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>1.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>1.292300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.061900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>1.243400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>1.083900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>1.247500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.070600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>1.271500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>1.034100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>1.244500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.020800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>1.300900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>1.031000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>1.309800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>0.811500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>1.658200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>0.559300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.560900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2125</td>\n",
       "      <td>0.547000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>1.563500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2175</td>\n",
       "      <td>0.540200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.543100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2225</td>\n",
       "      <td>0.531900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>1.557900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2275</td>\n",
       "      <td>0.561900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.596900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2325</td>\n",
       "      <td>0.552100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>1.558600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2375</td>\n",
       "      <td>0.561800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.560700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2425</td>\n",
       "      <td>0.550600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>1.520200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>0.559900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.616200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2525</td>\n",
       "      <td>0.600300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>1.530200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2575</td>\n",
       "      <td>0.534000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.459000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2625</td>\n",
       "      <td>0.541000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>1.568700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>0.548800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.553900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2725</td>\n",
       "      <td>0.559700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>1.476500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2775</td>\n",
       "      <td>0.539300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.374300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2825</td>\n",
       "      <td>0.486900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>1.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2875</td>\n",
       "      <td>0.537000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.501000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2925</td>\n",
       "      <td>0.565100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>1.557900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2975</td>\n",
       "      <td>0.545300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.588800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3025</td>\n",
       "      <td>0.549000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3036, training_loss=1.227531315309728, metrics={'train_runtime': 7592.7279, 'train_samples_per_second': 3.202, 'train_steps_per_second': 0.4, 'total_flos': 2.418327118824653e+16, 'train_loss': 1.227531315309728, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84829ebc-fb28-4d8c-9d4e-b16a98670377",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(\"trained-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8923807-6cd6-4790-9df9-a3813838332d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 2344/2344 [03:20<00:00, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.883\n",
      "Accuracy for label 0: 0.906\n",
      "Accuracy for label 1: 0.849\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90      1388\n",
      "           1       0.86      0.85      0.86       956\n",
      "\n",
      "    accuracy                           0.88      2344\n",
      "   macro avg       0.88      0.88      0.88      2344\n",
      "weighted avg       0.88      0.88      0.88      2344\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1258  130]\n",
      " [ 144  812]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test, model, tokenizer)\n",
    "evaluate(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
